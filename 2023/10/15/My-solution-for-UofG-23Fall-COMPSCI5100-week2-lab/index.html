<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>My solution for UofG 23Fall COMPSCI5100 week2 lab | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="Linear regression lab 2        Aims Practice general linear regression with polynomial and RBF  Choose the order of polynomials with cross validation Practice ridge regression  Tasks Rescale Write fun">
<meta property="og:type" content="article">
<meta property="og:title" content="My solution for UofG 23Fall COMPSCI5100 week2 lab">
<meta property="og:url" content="http://example.com/2023/10/15/My-solution-for-UofG-23Fall-COMPSCI5100-week2-lab/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="Linear regression lab 2        Aims Practice general linear regression with polynomial and RBF  Choose the order of polynomials with cross validation Practice ridge regression  Tasks Rescale Write fun">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/img/output_6_1.png">
<meta property="og:image" content="http://example.com/img/output_14_1.png">
<meta property="og:image" content="http://example.com/img/output_18_1.png">
<meta property="og:image" content="http://example.com/img/output_22_1.png">
<meta property="og:image" content="http://example.com/img/output_24_1.png">
<meta property="og:image" content="http://example.com/img/output_26_1.png">
<meta property="og:image" content="http://example.com/img/output_32_1.png">
<meta property="article:published_time" content="2023-10-15T16:23:30.000Z">
<meta property="article:modified_time" content="2023-10-21T17:42:07.164Z">
<meta property="article:author" content="Joseph Wang">
<meta property="article:tag" content="Machine Learning">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/img/output_6_1.png">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<meta name="generator" content="Hexo 7.0.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Search"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="custom-layout-My-solution-for-UofG-23Fall-COMPSCI5100-week2-lab" class="h-entry article article-type-custom-layout" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/10/15/My-solution-for-UofG-23Fall-COMPSCI5100-week2-lab/" class="article-date">
  <time class="dt-published" datetime="2023-10-15T16:23:30.000Z" itemprop="datePublished">2023-10-15</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      My solution for UofG 23Fall COMPSCI5100 week2 lab
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h3>Linear regression lab 2</h3>


<!-- Add the MathJax script within your blog post -->
<script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<hr>
<h4 id="Aims"><a href="#Aims" class="headerlink" title="Aims"></a>Aims</h4><ul>
<li>Practice general linear regression with polynomial and RBF </li>
<li>Choose the order of polynomials with cross validation</li>
<li>Practice ridge regression</li>
</ul>
<h4 id="Tasks"><a href="#Tasks" class="headerlink" title="Tasks"></a>Tasks</h4><ul>
<li>Rescale</li>
<li>Write functions to construct the design matrix, $X$, with polynomials and RBFs</li>
<li>Implement cross-validation to choose the right polynoimal order</li>
<li>Test polynoimal regression and cross-validation on new data where the true order is known</li>
<li>Test ridge regression</li>
<li>Test linear regression with the RBF</li>
</ul>
<span id="more"></span>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"></span><br><span class="line">x_test = np.linspace(<span class="number">2012</span>,<span class="number">2012</span>, <span class="number">1</span>)[:,<span class="literal">None</span>] <span class="comment"># test data</span></span><br><span class="line">x_test</span><br></pre></td></tr></table></figure>




<pre><code>array([[2012.]])
</code></pre>
<h4 id="Task-1-Again-we-start-by-loading-the-Olympic-100m-men’s-data"><a href="#Task-1-Again-we-start-by-loading-the-Olympic-100m-men’s-data" class="headerlink" title="Task 1: Again, we start by loading the Olympic 100m men’s data"></a>Task 1: Again, we start by loading the Olympic 100m men’s data</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> pylab <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">data = np.loadtxt(<span class="string">&#x27;olympic100m.txt&#x27;</span>, delimiter=<span class="string">&#x27;,&#x27;</span>) <span class="comment"># make sure olympic100m.txt is in the right folder</span></span><br><span class="line">x = data[:,<span class="number">0</span>][:,<span class="literal">None</span>] <span class="comment"># make x a matrix</span></span><br><span class="line">t = data[:,<span class="number">1</span>][:,<span class="literal">None</span>] <span class="comment"># make t a column vector </span></span><br></pre></td></tr></table></figure>

<h4 id="Task-2-Perform-Polynomial-Regression-on-the-Olympic-data"><a href="#Task-2-Perform-Polynomial-Regression-on-the-Olympic-data" class="headerlink" title="Task 2: Perform Polynomial Regression on the Olympic data"></a>Task 2: Perform Polynomial Regression on the Olympic data</h4><h4 id="Task-2-1-Rescale-x"><a href="#Task-2-1-Rescale-x" class="headerlink" title="Task 2.1 Rescale $x$"></a>Task 2.1 Rescale $x$</h4><p>We rescale $x$ to make it small. Doing so will stablise the computatoin, otherwise it quickly becomes unfeasible to fit polynomials over ~$2000$. Let’s test the following two options:</p>
<ul>
<li>Option 1: <code>(x-1896)/40</code></li>
<li>Option 2: <code>(x-np.mean(x))/np.std(x) </code></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">transform</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> (x-np.mean(x))/np.std(x)  <span class="comment"># copy the code above to perform different rescaling</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Test both options</span></span><br><span class="line">x = transform(x) <span class="comment"># rescale x here</span></span><br><span class="line">plt.plot(x, t, <span class="string">&#x27;ro&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Rescaled years&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Time (seconds)&#x27;</span>)</span><br></pre></td></tr></table></figure>




<pre><code>Text(0, 0.5, &#39;Time (seconds)&#39;)
</code></pre>
<p><img src="/../img/output_6_1.png" alt="png"></p>
<h4 id="Task-2-2-Write-you-own-function-to-construct-the-design-matrix-with-polynomials"><a href="#Task-2-2-Write-you-own-function-to-construct-the-design-matrix-with-polynomials" class="headerlink" title="Task 2.2 Write you own function to construct the design matrix with polynomials"></a>Task 2.2 Write you own function to construct the design matrix with polynomials</h4><p>$$<br>\mathbf{X} &#x3D; \begin{bmatrix}<br>1 &amp; x_{1} &amp; x_{1}^2 &amp; \dots &amp; x_{1}^K<br>\newline<br>1 &amp; x_{2} &amp; x_{2}^2 &amp; \dots &amp; x_{2}^K<br>\newline<br>\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots<br>\newline<br>1 &amp; x_{N} &amp; x_{N}^2 &amp; \dots &amp; x_{N}^K<br>\end{bmatrix}<br>$$  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">make_polynomial</span>(<span class="params">x, maxorder</span>): <span class="comment"># The np.hstack function can be very helpful</span></span><br><span class="line">    X = np.ones_like(x) </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,maxorder+<span class="number">1</span>):</span><br><span class="line">        X = np.hstack((X,x**i))</span><br><span class="line">    <span class="keyword">return</span>(X) </span><br></pre></td></tr></table></figure>

<h4 id="Task-2-3-Construct-the-design-matrix-with-a-predefined-maximum-polynomial-order"><a href="#Task-2-3-Construct-the-design-matrix-with-a-predefined-maximum-polynomial-order" class="headerlink" title="Task 2.3 Construct the design matrix with a predefined maximum polynomial order"></a>Task 2.3 Construct the design matrix with a predefined maximum polynomial order</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">poly_order = <span class="number">9</span></span><br><span class="line">X_train = make_polynomial(x, poly_order) </span><br></pre></td></tr></table></figure>

<h4 id="Task-2-4-Fit-a-linear-regression-model-with-polynomial-matrix-and-print-out-the-training-loss"><a href="#Task-2-4-Fit-a-linear-regression-model-with-polynomial-matrix-and-print-out-the-training-loss" class="headerlink" title="Task 2.4 Fit a linear regression model with polynomial matrix and print out the training loss"></a>Task 2.4 Fit a linear regression model with polynomial matrix and print out the training loss</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line">poly_reg = LinearRegression().fit(X_train, t) <span class="comment"># Fit a linear model</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;loss at order &#x27;</span>, poly_order, <span class="string">&#x27; :&#x27;</span>, np.mean((t-poly_reg.predict(X_train))**<span class="number">2</span> ) )</span><br></pre></td></tr></table></figure>

<pre><code>loss at order  9  : 0.015317351464102994
</code></pre>
<h4 id="Task-2-5-Plot-the-fitted-model-and-data"><a href="#Task-2-5-Plot-the-fitted-model-and-data" class="headerlink" title="Task 2.5 Plot the fitted model and data"></a>Task 2.5 Plot the fitted model and data</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">x_test = np.linspace(<span class="number">1880</span>,<span class="number">2020</span>, <span class="number">100</span>)[:,<span class="literal">None</span>] <span class="comment"># test data</span></span><br><span class="line">x_test = transform(x_test) <span class="comment"># do the same rescaling to the test data </span></span><br><span class="line">X_test = make_polynomial(x_test, poly_order) <span class="comment"># construct the polynomial matrix for test data</span></span><br><span class="line">f_test = poly_reg.predict(X_test)</span><br><span class="line">plt.plot(x_test,f_test,<span class="string">&#x27;b-&#x27;</span>,linewidth=<span class="number">2</span>) <span class="comment"># plot the fitted data</span></span><br><span class="line">plt.scatter(x,t) <span class="comment"># draw a scatter plot</span></span><br><span class="line">plt.xlabel(<span class="string">&#x27;Years&#x27;</span>) <span class="comment"># always label x&amp;y-axis</span></span><br><span class="line">plt.ylabel(<span class="string">&#x27;Time (seconds)&#x27;</span>) <span class="comment"># always label x&amp;y-axis</span></span><br></pre></td></tr></table></figure>




<pre><code>Text(0, 0.5, &#39;Time (seconds)&#39;)
</code></pre>
<p><img src="/../img/output_14_1.png" alt="png"></p>
<h3 id="Task-3-Choosing-Polynomial-order-with-Cross-Validation"><a href="#Task-3-Choosing-Polynomial-order-with-Cross-Validation" class="headerlink" title="Task 3: Choosing Polynomial order with Cross-Validation"></a>Task 3: Choosing Polynomial order with Cross-Validation</h3><h4 id="Task-3-1-Cross-Validation-with-a-given-Polynomial-order"><a href="#Task-3-1-Cross-Validation-with-a-given-Polynomial-order" class="headerlink" title="Task 3.1: Cross-Validation with a given Polynomial order."></a>Task 3.1: Cross-Validation with a given Polynomial order.</h4><p>Reference for <code>KFold</code>: <a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html">https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> KFold </span><br><span class="line">cv = KFold(n_splits = <span class="number">5</span>) <span class="comment"># </span></span><br><span class="line">loss = []</span><br><span class="line">reg = LinearRegression()</span><br><span class="line"></span><br><span class="line">poly_order = <span class="number">9</span></span><br><span class="line">X_train = make_polynomial(x, poly_order)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> train_index, test_index <span class="keyword">in</span> cv.split(X_train): </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;TRAIN:&#x27;</span>, train_index, <span class="string">&#x27;TEST:&#x27;</span>, test_index)</span><br><span class="line">    X_train_cv, X_test_cv = X_train[train_index], X_train[test_index] <span class="comment"># select X for training and testing</span></span><br><span class="line">    t_train_cv, t_test_cv = t[train_index], t[test_index] <span class="comment"># select t for training and testing</span></span><br><span class="line">    reg.fit(X_train_cv, t_train_cv) <span class="comment"># fit a model on the training data </span></span><br><span class="line">    loss.append( np.mean(( t_test_cv - reg.predict(X_test_cv) )**<span class="number">2</span>  ) ) <span class="comment"># compute loss on test data</span></span><br><span class="line"><span class="built_in">print</span>(loss) <span class="comment"># print loss across fold</span></span><br><span class="line"><span class="built_in">print</span>(np.mean(loss)) <span class="comment"># print average loss at this polynomial order</span></span><br></pre></td></tr></table></figure>

<pre><code>TRAIN: [ 6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26] TEST: [0 1 2 3 4 5]
TRAIN: [ 0  1  2  3  4  5 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26] TEST: [ 6  7  8  9 10 11]
TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 17 18 19 20 21 22 23 24 25 26] TEST: [12 13 14 15 16]
TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 22 23 24 25 26] TEST: [17 18 19 20 21]
TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21] TEST: [22 23 24 25 26]
[2331.177225272578, 0.4133916880374983, 0.03962632115541264, 0.1314825502663531, 107.12933254068062]
487.77821167454357
</code></pre>
<h4 id="Task-3-2-Cross-Validation-for-a-range-of-Polynomial-orders"><a href="#Task-3-2-Cross-Validation-for-a-range-of-Polynomial-orders" class="headerlink" title="Task 3.2: Cross-Validation for a range of Polynomial orders."></a>Task 3.2: Cross-Validation for a range of Polynomial orders.</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">cv = KFold(n_splits = <span class="number">10</span>)</span><br><span class="line">reg = LinearRegression()</span><br><span class="line">all_loss = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">9</span>):  <span class="comment"># 1st for loop over polynomial orders </span></span><br><span class="line">    poly_order = i</span><br><span class="line">    X_train = make_polynomial(x, poly_order)</span><br><span class="line">    loss_at_order = []</span><br><span class="line">    <span class="keyword">for</span> train_index, test_index <span class="keyword">in</span> cv.split(X_train): <span class="comment"># 2nd for loop for cross-validation</span></span><br><span class="line">        X_train_cv, X_test_cv = X_train[train_index], X_train[test_index]</span><br><span class="line">        t_train_cv, t_test_cv = t[train_index], t[test_index]</span><br><span class="line">        reg.fit(X_train_cv, t_train_cv)</span><br><span class="line">        loss_at_order.append( np.mean(( t_test_cv - reg.predict(X_test_cv) )**<span class="number">2</span>  ) ) <span class="comment"># collect loss at fold</span></span><br><span class="line">    all_loss.append(np.mean(loss_at_order)) <span class="comment"># collect loss at order</span></span><br><span class="line">plt.plot(np.log(all_loss), <span class="string">&#x27;bo-&#x27;</span>) <span class="comment"># plot log(loss) at order</span></span><br><span class="line">plt.xlabel(<span class="string">&#x27;Polynomial Order&#x27;</span>) <span class="comment"># always label x&amp;y-axis</span></span><br><span class="line">plt.ylabel(<span class="string">&#x27;Log Loss&#x27;</span>) <span class="comment"># always label x&amp;y-axis</span></span><br></pre></td></tr></table></figure>




<pre><code>Text(0, 0.5, &#39;Log Loss&#39;)
</code></pre>
<p><img src="/../img/output_18_1.png" alt="png"></p>
<h3 id="Task-4-Cross-Validation-for-Polynomial-order-on-new-data"><a href="#Task-4-Cross-Validation-for-Polynomial-order-on-new-data" class="headerlink" title="Task 4: Cross-Validation for Polynomial order on new data"></a>Task 4: Cross-Validation for Polynomial order on new data</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">np.random.seed(<span class="number">1</span>) <span class="comment"># fix random seed such that every time we get the same random numbers</span></span><br><span class="line"></span><br><span class="line">N = <span class="number">100</span> <span class="comment"># total number of data points </span></span><br><span class="line">x = <span class="number">10</span>*np.random.rand(N,<span class="number">1</span>) - <span class="number">5</span> <span class="comment"># generate random x</span></span><br><span class="line">t = <span class="number">5</span>*x**<span class="number">3</span> - x**<span class="number">2</span> + x + <span class="number">200</span>*np.random.randn(N,<span class="number">1</span>) <span class="comment"># generate t according to the true model with additive noise</span></span><br><span class="line"></span><br><span class="line">N_independent_test = <span class="number">50</span> <span class="comment"># total number of independent testing data points </span></span><br><span class="line">x_independent_test = <span class="number">10</span>*np.random.rand(N_independent_test,<span class="number">1</span>) - <span class="number">5</span> <span class="comment"># generate independent testing x</span></span><br><span class="line">t_independent_test = <span class="number">5</span>*x_independent_test**<span class="number">3</span> - x_independent_test**<span class="number">2</span> + x_independent_test + <span class="number">200</span>*np.random.randn(N_independent_test,<span class="number">1</span>) <span class="comment"># generate independent testing t with noise</span></span><br></pre></td></tr></table></figure>

<h3 id="Plot-new-data"><a href="#Plot-new-data" class="headerlink" title="Plot new data."></a>Plot new data.</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(x, t, <span class="string">&#x27;ro&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;x&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;t&#x27;</span>)</span><br></pre></td></tr></table></figure>




<pre><code>Text(0, 0.5, &#39;t&#39;)
</code></pre>
<p><img src="/../img/output_22_1.png" alt="png"></p>
<h4 id="Task-4-1-Redo-Cross-Validation-for-Polynomial-order-on-new-data-Plot-CV-loss-training-loss-and-loss-on-the-independent-test-set"><a href="#Task-4-1-Redo-Cross-Validation-for-Polynomial-order-on-new-data-Plot-CV-loss-training-loss-and-loss-on-the-independent-test-set" class="headerlink" title="Task 4.1: Redo Cross-Validation for Polynomial order on new data. Plot CV loss, training loss, and loss on the independent test set"></a>Task 4.1: Redo Cross-Validation for Polynomial order on new data. Plot CV loss, training loss, and loss on the independent test set</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">cv = KFold(n_splits = <span class="number">10</span>)</span><br><span class="line">reg = LinearRegression() <span class="comment"># model for CV</span></span><br><span class="line">reg_train = LinearRegression() <span class="comment"># model for loss on training and independent test </span></span><br><span class="line"></span><br><span class="line">all_loss = []</span><br><span class="line">all_loss_trian = []</span><br><span class="line">all_loss_independent_test = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">9</span>):  <span class="comment"># 1st for loop over polynomial order</span></span><br><span class="line">    </span><br><span class="line">    poly_order = i </span><br><span class="line">    </span><br><span class="line">   </span><br><span class="line">    X_train = make_polynomial(x, poly_order) <span class="comment"># construct polynomial matrix for all training data</span></span><br><span class="line">    reg_train.fit(X_train, t) <span class="comment"># fit model on all training data</span></span><br><span class="line">    all_loss_trian.append(  np.mean(( t - reg_train.predict(X_train))**<span class="number">2</span>)) <span class="comment"># collect training loss</span></span><br><span class="line">    </span><br><span class="line">    X_independent_test = make_polynomial(x_independent_test, poly_order) <span class="comment">#construct polynomial matrix for the independent test data</span></span><br><span class="line">    all_loss_independent_test.append(</span><br><span class="line">        np.mean(( t_independent_test - </span><br><span class="line">                 reg_train.predict(X_independent_test))**<span class="number">2</span>)) <span class="comment"># collect loss on independent test data</span></span><br><span class="line">    </span><br><span class="line">    loss_at_order = [] </span><br><span class="line">    <span class="keyword">for</span> train_index, test_index <span class="keyword">in</span> cv.split(X_train): <span class="comment"># 2nd for loop over folds</span></span><br><span class="line">        X_train_cv, X_test_cv = X_train[train_index], X_train[test_index]</span><br><span class="line">        t_train_cv, t_test_cv = t[train_index], t[test_index]</span><br><span class="line">        reg.fit(X_train_cv, t_train_cv)</span><br><span class="line">        loss_at_order.append( np.mean(( t_test_cv - reg.predict(X_test_cv) )**<span class="number">2</span>  ) )</span><br><span class="line">    all_loss.append(np.mean(loss_at_order)) </span><br><span class="line"></span><br><span class="line">plt.plot(np.log(all_loss), <span class="string">&#x27;ro-&#x27;</span>)</span><br><span class="line">plt.plot(np.log(all_loss_trian), <span class="string">&#x27;bo-&#x27;</span>)</span><br><span class="line">plt.plot(np.log(all_loss_independent_test), <span class="string">&#x27;go-&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Polynomial Order&#x27;</span>) <span class="comment"># always label x&amp;y-axis</span></span><br><span class="line">plt.ylabel(<span class="string">&#x27;Log Loss&#x27;</span>) <span class="comment"># always label x&amp;y-axis</span></span><br></pre></td></tr></table></figure>




<pre><code>Text(0, 0.5, &#39;Log Loss&#39;)
</code></pre>
<p><img src="/../img/output_24_1.png" alt="png"></p>
<h3 id="Task-5-Polynomial-Linear-Regression-with-L2-regression"><a href="#Task-5-Polynomial-Linear-Regression-with-L2-regression" class="headerlink" title="Task 5: Polynomial Linear Regression with L2 regression."></a>Task 5: Polynomial Linear Regression with L2 regression.</h3><p>$$ \hat{\mathbf{w}}_{ridge} &#x3D; \underset{\mathbf{w} }{\mathrm{argmin}}<br> \frac{1}{N} (\mathbf{t} - \mathbf{X}\mathbf{w} )^{T} (\mathbf{t} - \mathbf{X}\mathbf{w} ) + \alpha \mathbf{w}^T \mathbf{w}$$<br>check out <a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html">https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html</a> for <code>Ridge</code><br>check out <a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html">https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html</a> for <code>GridSearchCV</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Ridge</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line"></span><br><span class="line">poly_order = <span class="number">10</span> </span><br><span class="line">X_train = make_polynomial(x, poly_order) <span class="comment"># construct polynomial matrix on training data</span></span><br><span class="line"></span><br><span class="line">x_test = np.linspace(-<span class="number">5</span>,<span class="number">5</span>,<span class="number">100</span>)[:,<span class="literal">None</span>] <span class="comment"># generate x_test for plotting</span></span><br><span class="line">X_test = make_polynomial(x_test, poly_order) <span class="comment"># construct polynomial matrix on x_test</span></span><br><span class="line"></span><br><span class="line">ridge = Ridge() <span class="comment"># call ridge model</span></span><br><span class="line">parameters = &#123;<span class="string">&#x27;alpha&#x27;</span>: np.linspace(<span class="number">1</span>, <span class="number">10</span>, <span class="number">20</span>)&#125; <span class="comment"># set out search grid for alpha</span></span><br><span class="line">ridge_model = GridSearchCV(ridge, parameters, scoring = <span class="string">&#x27;neg_mean_squared_error&#x27;</span>, cv=<span class="number">5</span>) <span class="comment"># Define CV on the search grid to define alpha</span></span><br><span class="line">ridge_model.fit(X_train, t) <span class="comment"># Fit training data</span></span><br><span class="line"></span><br><span class="line">plt.plot(x_test, ridge_model.predict(X_test)) <span class="comment"># plot the model</span></span><br><span class="line">plt.scatter(x,t) <span class="comment"># draw a scatter plot</span></span><br><span class="line">plt.xlabel(<span class="string">&#x27;Years&#x27;</span>) <span class="comment"># always label x&amp;y-axis</span></span><br><span class="line">plt.ylabel(<span class="string">&#x27;Time (seconds)&#x27;</span>) <span class="comment"># always label x&amp;y-axis</span></span><br></pre></td></tr></table></figure>




<pre><code>Text(0, 0.5, &#39;Time (seconds)&#39;)
</code></pre>
<p><img src="/../img/output_26_1.png" alt="png"></p>
<h3 id="Task-6-Practice-linear-regression-with-RBF"><a href="#Task-6-Practice-linear-regression-with-RBF" class="headerlink" title="Task 6 Practice linear regression with RBF."></a>Task 6 Practice linear regression with RBF.</h3><p>Write you own function to construct the design matrix with RBF</p>
<p>$$ h_k(x) &#x3D; \exp \left( -\frac{ (x-\mbox{center}[k]) ^2}{2\mbox{width}}  \right)$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">make_rbf</span>(<span class="params">x, center, width</span>):  <span class="comment"># again np.hstack is very helpful</span></span><br><span class="line">    X = np.exp( -<span class="number">0.5</span>*(x-center[<span class="number">0</span>])**<span class="number">2</span>/width) </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span> (<span class="built_in">len</span>(center))[<span class="number">1</span>:]:</span><br><span class="line">        X = np.hstack( (X,np.exp( -<span class="number">0.5</span>*(x-center[i])**<span class="number">2</span>/width)) )</span><br><span class="line">    <span class="keyword">return</span>(X)</span><br></pre></td></tr></table></figure>

<h4 id="Task-6-2-Construct-the-design-matrix-with-x-itself-as-the-center-parameter"><a href="#Task-6-2-Construct-the-design-matrix-with-x-itself-as-the-center-parameter" class="headerlink" title="Task 6.2 Construct  the design matrix with $x$ itself as the center parameter"></a>Task 6.2 Construct  the design matrix with $x$ itself as the center parameter</h4><p>Start with <code>width = 10</code> and test different values</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">center = x </span><br><span class="line">width = <span class="number">10</span></span><br><span class="line">X_rbf = make_rbf(x, center, width)</span><br><span class="line">X_rbf.shape</span><br><span class="line">x.shape</span><br><span class="line">x</span><br></pre></td></tr></table></figure>




<pre><code>array([[-0.82977995],
       [ 2.20324493],
       [-4.99885625],
       [-1.97667427],
       [-3.53244109],
       [-4.07661405],
       [-3.13739789],
       [-1.54439273],
       [-1.03232526],
       [ 0.38816734],
       [-0.80805486],
       [ 1.852195  ],
       [-2.9554775 ],
       [ 3.78117436],
       [-4.72612407],
       [ 1.7046751 ],
       [-0.82695198],
       [ 0.58689828],
       [-3.59613061],
       [-3.01898511],
       [ 3.00744569],
       [ 4.68261576],
       [-1.86575822],
       [ 1.92322616],
       [ 3.76389152],
       [ 3.94606664],
       [-4.14955789],
       [-4.60945217],
       [-3.3016958 ],
       [ 3.78142503],
       [-4.01653166],
       [-0.78892375],
       [ 4.5788953 ],
       [ 0.33165285],
       [ 1.91877114],
       [-1.84484369],
       [ 1.86500928],
       [ 3.34625672],
       [-4.81711723],
       [ 2.50144315],
       [ 4.88861089],
       [ 2.48165654],
       [-2.19556008],
       [ 2.89279328],
       [-3.96773993],
       [-0.52106474],
       [ 4.08595503],
       [-2.06385852],
       [-2.12224661],
       [-3.69971428],
       [-4.80633042],
       [ 1.78835533],
       [-2.88371884],
       [-2.34453341],
       [-0.08426841],
       [-4.46637455],
       [ 0.74117605],
       [-3.53271425],
       [ 0.89305537],
       [ 1.9975836 ],
       [-3.97665571],
       [-0.85944012],
       [ 1.94400158],
       [-0.8582073 ],
       [-4.50046541],
       [ 0.35896406],
       [ 1.63794645],
       [ 0.14889112],
       [ 4.44594756],
       [ 0.86555041],
       [ 4.03401915],
       [-3.62525296],
       [-3.60723653],
       [ 3.07391289],
       [-1.02323163],
       [-3.34645803],
       [ 4.2750858 ],
       [-1.5223414 ],
       [ 2.50812103],
       [ 2.25997985],
       [ 3.83306091],
       [ 1.23672207],
       [ 2.50942434],
       [-1.51101658],
       [-2.30072108],
       [ 3.95886218],
       [-0.7190881 ],
       [ 4.64840047],
       [ 1.63441498],
       [ 1.2169572 ],
       [-3.85254027],
       [ 4.49489259],
       [-0.50087867],
       [ 0.78389614],
       [-0.91863197],
       [-2.6297302 ],
       [ 4.03379521],
       [ 0.73679487],
       [-4.97129673],
       [ 1.17144914]])
</code></pre>
<h4 id="Task-6-2-Fit-a-linear-regression-model-with-X-constructed-by-RBF"><a href="#Task-6-2-Fit-a-linear-regression-model-with-X-constructed-by-RBF" class="headerlink" title="Task 6.2 Fit a linear regression model with X constructed by RBF"></a>Task 6.2 Fit a linear regression model with X constructed by RBF</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">reg = LinearRegression()</span><br><span class="line">reg.fit(X_rbf,t)</span><br><span class="line"></span><br><span class="line">X_test = make_rbf(x_test, center, width)</span><br><span class="line"></span><br><span class="line">plt.plot(x_test, reg.predict(X_test))</span><br><span class="line">plt.scatter(x,t) <span class="comment"># draw a scatter plot</span></span><br><span class="line">plt.xlabel(<span class="string">&#x27;t&#x27;</span>) <span class="comment"># always label x&amp;y-axis</span></span><br><span class="line">plt.ylabel(<span class="string">&#x27;x&#x27;</span>) <span class="comment"># always label x&amp;y-axis</span></span><br></pre></td></tr></table></figure>




<pre><code>Text(0, 0.5, &#39;x&#39;)
</code></pre>
<p><img src="/../img/output_32_1.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

<hr>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2023/10/15/My-solution-for-UofG-23Fall-COMPSCI5100-week2-lab/" data-id="clp635lpc0009bgfwd7fjc7qp" data-title="My solution for UofG 23Fall COMPSCI5100 week2 lab" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Machine-Learning/" rel="tag">Machine Learning</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/10/20/notice-for-java-assessment/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          notice for java assessment
        
      </div>
    </a>
  
  
    <a href="/2023/10/02/learning-from-scratch-2023-10-02/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">learning from scratch 2023-10-02</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Programming-2023tutorial/">-Programming -2023tutorial</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/c-Programming/" rel="tag">-c++ -Programming</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/deep-learning/" rel="tag">-deep learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Algorithm-Leetcode-Graph-Problems/" rel="tag">Algorithm, Leetcode, Graph Problems</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/COMPSCI4084/" rel="tag">COMPSCI4084</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Introduction-to-data-science-and-system/" rel="tag">Introduction to data science and system</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Machine-Learning/" rel="tag">Machine Learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/learning-from-scratch/" rel="tag">learning from scratch</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/machine-learning/" rel="tag">machine learning</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/c-Programming/" style="font-size: 10px;">-c++ -Programming</a> <a href="/tags/deep-learning/" style="font-size: 10px;">-deep learning</a> <a href="/tags/Algorithm-Leetcode-Graph-Problems/" style="font-size: 10px;">Algorithm, Leetcode, Graph Problems</a> <a href="/tags/COMPSCI4084/" style="font-size: 10px;">COMPSCI4084</a> <a href="/tags/Introduction-to-data-science-and-system/" style="font-size: 10px;">Introduction to data science and system</a> <a href="/tags/Machine-Learning/" style="font-size: 15px;">Machine Learning</a> <a href="/tags/learning-from-scratch/" style="font-size: 20px;">learning from scratch</a> <a href="/tags/machine-learning/" style="font-size: 15px;">machine learning</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/09/">September 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/02/">February 2022</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2023/11/22/notice-for-5100-22-23-paper/">notice for 5100 22-23 paper</a>
          </li>
        
          <li>
            <a href="/2023/11/20/notice-for-5089-final-exam-lecture-3/">notice for 5089 final exam(lecture 3)</a>
          </li>
        
          <li>
            <a href="/2023/11/19/notice-for-5089-past-exam-paper/">notice for 5089 past exam paper</a>
          </li>
        
          <li>
            <a href="/2023/10/24/notice-for-idss-week5-optimization2/">notice for idss week5 optimization2</a>
          </li>
        
          <li>
            <a href="/2023/10/22/notice-for-idss-week4-optimization/">notice for idss week4 - optimization</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2023 Joseph Wang<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>